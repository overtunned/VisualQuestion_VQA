{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle \n",
    "from collections import Counter\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modify_entry(label_list,entry):\n",
    "    label_set=entry['labels']\n",
    "    label_name=[label_list[val] for id,val in enumerate(label_set)]\n",
    "    entry['Label_name']=label_name\n",
    "    return(entry)\n",
    "\n",
    "pickle_file=\"/home/ok_sikha/abhishek/VisualQuestion_VQA/data/cache/train_target.pkl\"\n",
    "val_pickle_file=\"/home/ok_sikha/abhishek/VisualQuestion_VQA/data/cache/val_target.pkl\"\n",
    "label_map_file=\"/home/ok_sikha/abhishek/VisualQuestion_VQA/data/cache/trainval_label2ans.pkl\"\n",
    "num_classes_select=3000\n",
    "dataroot='/home/ok_sikha/abhishek/VisualQuestion_VQA/data'\n",
    "\n",
    "data=pickle.load(open(pickle_file,'rb'))\n",
    "answer_data=pickle.load(open(label_map_file,'rb'))\n",
    "validation_data=pickle.load(open(val_pickle_file,'rb'))\n",
    "\n",
    "#print(len(data))\n",
    "label_list=[]\n",
    "# print(answer_data)\n",
    "\n",
    "\n",
    "for data_sample in data:\n",
    "    #print(data_sample.keys())\n",
    "    score=data_sample['scores']\n",
    "    labels=data_sample['labels']\n",
    "    if(len(score)>0):\n",
    "        max_id=score.index(max(score))\n",
    "        label_list.append(labels[max_id])\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(len(label_list))\n",
    "count_set=Counter(label_list)\n",
    "y = OrderedDict(count_set.most_common())\n",
    "#scount_set=OrderedDict(label_list)\n",
    "keys_set=list(y.keys())[:num_classes_select]\n",
    "keys_name=[answer_data[id] for id in keys_set]\n",
    "print(len(keys_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_name[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dict_set=dict(zip(keys_name,list(y.values())))\n",
    "#sorted_x = sorted(dict_set.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df=pd.DataFrame({'Label_names':keys_name,'Occurences':list(dict_set.items()),'Label_indices':keys_set})\n",
    "df.to_csv('../data/Train_Class_Distribution.csv',columns=['Label_names','Label_indices','Occurences'],index=False)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(range(num_classes_select)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the hdf5 features from rcnn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import h5py\n",
    "train_rcnn_pickle_file=\"/home/ok_sikha/abhishek/VisualQuestion_VQA/data/train36_imgid2idx.pkl\"\n",
    "pkl_data=pickle.load(open(train_rcnn_pickle_file,'rb'))\n",
    "print('Loading the hdf5 features from rcnn')\n",
    "h5_path=os.path.join('/home/ok_sikha/abhishek/VisualQuestion_VQA/data','train36.hdf5')\n",
    "hf=h5py.File(h5_path, 'r')\n",
    "features=hf.get('image_features')\n",
    "\n",
    "\n",
    "if(1 in pkl_data):\n",
    "    idx=pkl_data[1]\n",
    "    feat=torch.from_numpy(features[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 1.2020e+00,  ..., 0.0000e+00, 6.7555e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 1.0598e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 5.9250e+00,  ..., 1.0031e+01, 0.0000e+00,\n",
       "         1.1795e+00],\n",
       "        ...,\n",
       "        [5.0625e-01, 0.0000e+00, 9.6794e-03,  ..., 3.5051e-01, 0.0000e+00,\n",
       "         4.1708e-02],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.0504e+00, 8.5751e-01,\n",
       "         1.0846e-01],\n",
       "        [1.2219e-01, 0.0000e+00, 4.8807e-02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "entry_1000_classes=[]\n",
    "class_list_set=set(keys_set[0:num_classes_select])\n",
    "\n",
    "print('Sampling training data')\n",
    "label_sampled=[]\n",
    "for data_sample in tqdm(data):\n",
    "    #print(data_sample.keys())\n",
    "    score=data_sample['scores']\n",
    "    labels=data_sample['labels']\n",
    "    if(len(score)>0):\n",
    "        max_id=score.index(max(score))\n",
    "        label_question=labels[max_id]\n",
    "        if(label_question in class_list_set):\n",
    "            label_sampled.append(label_question)\n",
    "            data_sample=modify_entry(answer_data,data_sample)\n",
    "            entry_1000_classes.append(data_sample)\n",
    "\n",
    "print('Sampling validation data')\n",
    "label_validation_sampled=[]\n",
    "entry_validation_1000_classes=[]\n",
    "for data_sample in tqdm(validation_data):\n",
    "    #print(data_sample.keys())\n",
    "    score=data_sample['scores']\n",
    "    labels=data_sample['labels']\n",
    "    if(len(score)>0):\n",
    "        max_id=score.index(max(score))\n",
    "        label_question=labels[max_id]\n",
    "        if(label_question in class_list_set):\n",
    "            label_validation_sampled.append(label_question)\n",
    "            data_sample=modify_entry(answer_data,data_sample)\n",
    "            entry_validation_1000_classes.append(data_sample)\n",
    "\n",
    "\n",
    "label_sample_set=list(set(label_sampled))\n",
    "print(len(label_sample_set))\n",
    "print(len(list(class_list_set)))\n",
    "\n",
    "intersect_list=set(label_sampled).intersection(list(class_list_set))\n",
    "\n",
    "\n",
    "with open('../data/train_target_yes_no_bin.pkl','wb') as f:\n",
    "    pickle.dump(entry_1000_classes,f)\n",
    "with open('../data/validation_target_yes_no_bin.pkl','wb') as f:\n",
    "    pickle.dump(entry_validation_1000_classes,f)\n",
    "\n",
    "\n",
    "\n",
    "print('Resampling the training json data')\n",
    "train_question_path = os.path.join(\n",
    "        dataroot, 'vgenome_train2021_questions.json')\n",
    "train_questions = sorted(json.load(open(train_question_path)),\n",
    "                       key=lambda x: x['question_id'])\n",
    "\n",
    "\n",
    "print('Finding the matches in training data')\n",
    "question_train_tot_id=[entr['question_id'] for entr in train_questions]\n",
    "question_train_sample_id=[entr['question_id'] for entr in entry_1000_classes]\n",
    "set_sample_train=set(question_train_sample_id)\n",
    "id_matches_train=[id for id,val in enumerate(question_train_tot_id) if val in set_sample_train]\n",
    "question_train_set=[train_questions[id_new] for id_new in id_matches_train]\n",
    "print(len(question_train_set))\n",
    "print(len(entry_1000_classes))\n",
    "train_questions_dict={}\n",
    "train_questions_dict['questions']=question_train_set\n",
    "with open('data/vgenome_train2021_2_questions.json', 'w') as fp:\n",
    "    json.dump(train_questions_dict, fp)\n",
    "\n",
    "\n",
    "\n",
    "print('Resampling the validation json data')\n",
    "valid_question_path = os.path.join(\n",
    "        dataroot, 'vgenome_val2021_questions.json')\n",
    "valid_questions = sorted(json.load(open(valid_question_path)),\n",
    "                       key=lambda x: x['question_id'])\n",
    "\n",
    "\n",
    "print('Finding the matches in validation data')\n",
    "question_valid_tot_id=[entr['question_id'] for entr in valid_questions]\n",
    "question_valid_sample_id=[entr['question_id'] for entr in entry_validation_1000_classes]\n",
    "set_sample_valid=set(question_valid_sample_id)\n",
    "id_matches_valid=[id for id,val in enumerate(question_valid_tot_id) if val in set_sample_valid]\n",
    "question_valid_set=[valid_questions[id_new] for id_new in id_matches_valid]\n",
    "print(len(question_valid_set))\n",
    "print(len(entry_validation_1000_classes))\n",
    "valid_questions_dict={}\n",
    "valid_questions_dict['questions']=question_valid_set\n",
    "with open('data/vgenome_val2021_2_questions.json', 'w') as fp:\n",
    "    json.dump(valid_questions_dict, fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#resampling to 1000 classes\n",
    "\n",
    "#iterator = iter(dict_set.items())\n",
    "#for i in range(5):\n",
    "#    print(next(iterator))\n",
    "\n",
    "#df = pd.DataFrame.from_dict(d, orient=\"index\")\n",
    "\n",
    "#print(list(count_set.values())[0:100])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
